{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOwW4XFYXnC6gq7TBKW15u+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdy9777/GitriniForkRepo/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00. pytorch Fundamentals\n",
        "\n",
        "resource link : https://www.learnpytorch.io/00_pytorch_fundamentals/"
      ],
      "metadata": {
        "id": "Q32vzZ7KqBnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbLoUbiIrg5W",
        "outputId": "667c0c99-d24c-4a2f-99de-ddad7085760a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## intro to Tensors\n",
        "\n",
        "### creating tensor\n",
        "scalar = torch.tensor(7)"
      ],
      "metadata": {
        "id": "43NK75xXxqOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a16Q2bjAyqQC",
        "outputId": "c77d4ccd-24a9-47c7-d0ab-5861c31c46cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get tensor back as Python int\n",
        "scalar.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYEzUdVGzUn6",
        "outputId": "e7b48014-eb91-4886-bc78-c5bb9a955a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector\n",
        "vector = torch.tensor([7,7])\n",
        "vector.ndim # numbeor of braket\n",
        "vector.shape # number of pairs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rzZlFhmzcxf",
        "outputId": "065500cc-e355-446c-8ccb-d22fd0d3cac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix matrix and tensor는 대문자 표기\n",
        "MATRIX = torch.tensor([[7,8],[9,10]])\n",
        "MATRIX.ndim # 2차원\n",
        "MATRIX.shape # 2*2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivX_kwjw0f6X",
        "outputId": "1efee16f-4db7-4893-d07f-09fa00cc227f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor\n",
        "TENSOR = torch.tensor([[[1,2,3],[3,6,9],[2,4,5]]])\n",
        "TENSOR.ndim # 3차원\n",
        "TENSOR.shape # 1*3*3 #1 <- 가장 바깥 브래킷 안의 요소 수, 3 <- 두번 째 바깥 3 <- 가장 내부 브래킷 요소 수)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5TB-TEh1Jhr",
        "outputId": "01b2e183-95f4-415b-bf35-888884e43e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random tensors\n",
        "why random tensors\n",
        "-> random tensors are important because the way many neural networks learn is that start with tensors full of random numbers and then adjust those random numbers to better represent the data\n"
      ],
      "metadata": {
        "id": "phyG-S16IUaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of size (3,4)\n",
        "random_tensor = torch.rand(3,4) # torch.rand(size=(3,3))과 같은 결과\n",
        "random_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RpX95GBIzGi",
        "outputId": "607ceae0-ac4e-489d-b4de-f4b532896d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor with similar shape to an image tensor\n",
        "random_tensor_image = torch.rand(size = (224,224,3)) # height, width, color_channel\n",
        "random_tensor_image.shape, random_tensor_image.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYZZM8uVJpy7",
        "outputId": "a3c56dab-e18a-4853-e465-9492faf7041d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zeroes and ones"
      ],
      "metadata": {
        "id": "EDSXU-Io0pKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all zeros\n",
        "zero = torch.zeros(size=(3,4)) # default data type is torch.float32\n",
        "zero"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk-ERdBe0sd2",
        "outputId": "14a6d7ba-5899-417f-ba53-3da4fea51240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all ones\n",
        "ones = torch.ones(size=(3, 4)) # default data type is torch.float32\n",
        "ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hwm_Rquo0_Kp",
        "outputId": "8ffdc66e-d42c-4b4b-ae28-d60c57e0fa67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a range of tensors and tensors-like"
      ],
      "metadata": {
        "id": "BcKJrLG81TD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use torch.arange()\n",
        "one_to_thousand = torch.arange(start = 1, end = 11, step = 1)\n",
        "one_to_thousand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9pi1H161moK",
        "outputId": "aa3f3b9f-6a83-4e59-8301-cc417648d62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tensors like\n",
        "ten_zeros = torch.zeros_like(input = one_to_thousand) # same shape of input\n",
        "ten_zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQOPKL9n2W-G",
        "outputId": "78a07df8-1792-40ed-c903-d182219df49f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor datatype\n",
        "**Note:** Tensor data-type is one of the 3 big errors you'll run into with Pytorch & Deep learning\n",
        "\n",
        "1. tensors not right data-type\n",
        "2. tensors not right shape\n",
        "3. tensors not on the right device"
      ],
      "metadata": {
        "id": "oxLjjVV93OKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# float32 tensor <- default data type\n",
        "float_32_tensor = torch.tensor([3.0,6.0,9.0], dtype = None) # dtype(what data type is), device(What device is your tensor on), requires_grad(whether or not to track gradients with tensors operations)\n",
        "float_32_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwxPHfTS3RU7",
        "outputId": "df7ce9ad-d037-40e6-fcaa-d1809481e8b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor = float_32_tensor.type(torch.float16)"
      ],
      "metadata": {
        "id": "mzTOMMwL7gWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_32 = torch.tensor([3,6,9],dtype= torch.int32)\n",
        "int_32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3uFfC2-8ZlN",
        "outputId": "5b632316-5be2-4e74-96d1-28ff9a15b210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 6, 9], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### getting information from tensors(tensor's attribute)\n",
        "1. tensor.dtype\n",
        "2. tensor.shape\n",
        "3. tensor.device"
      ],
      "metadata": {
        "id": "wXyHFYxV9H9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulating Tensors(tensor operations)\n",
        "\n",
        "Tensor operations include:\n",
        "* Addition\n",
        "* Subtraction\n",
        "* Multiplication(element-wise)\n",
        "* Division\n",
        "* Matrix multiplication(행렬곱)"
      ],
      "metadata": {
        "id": "yh5N4aTI1Q8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1,2,3])\n",
        "tensor + 100 # add 100 to all element\n",
        "tensor_mul = tensor * 10 # multiply 10 to all element\n",
        "tensor_min = tensor - 10 # subtract 10 to all element"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCBD7lQ913ew",
        "outputId": "ab83d9db-34ce-4315-bd6b-0e35a84d2869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([101, 102, 103])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in-bulit fuction\n",
        "torch.mul(tensor, 10)\n",
        "torch.add(tensor, 10)"
      ],
      "metadata": {
        "id": "ZSNS1LjE2Va8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix multiplication\n",
        "\n",
        "Two main ways of performing multiplications in neural networks and deep learning :\n",
        "\n",
        "1. Element-wise Multiplication\n",
        "2. Matrix multiplication"
      ],
      "metadata": {
        "id": "x0dv-4Jc2wF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# element-wise multiplication\n",
        "print(tensor*tensor)\n",
        "\n",
        "# 행렬곱\n",
        "print(torch.matmul(tensor,tensor))\n",
        "print(tensor @ tensor) # 같은 표현 torch.mm() 역시 행렬곱 표현"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aUyWQW65Bov",
        "outputId": "1d3027a4-8972-43d5-d2b1-46bfa378b91a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 4, 9])\n",
            "tensor(14)\n",
            "tensor(14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_a = torch.tensor([[1,2],[3,4],[5,6]])\n",
        "# print(tensor_a.shape)\n",
        "tensor_b = torch.tensor([[7,10],[8,11],[9,12]])\n",
        "\n",
        "print(torch.mm(tensor_a, tensor_b.T))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QisjCf3E7Lz3",
        "outputId": "21f6ad5b-2cab-464e-847f-acebbca1be74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## tensor min, max, mean (tensor aggregation)\n",
        "tensor = torch.arange(0,100,10)\n",
        "print(tensor)\n",
        "\n",
        "print(tensor)\n",
        "print(tensor.min()) # torch.min(tensor)\n",
        "print(tensor.max()) # torch.max(tensor)\n",
        "print(torch.mean(tensor.type(torch.float32))) # torch.mean(tensor)\n",
        "print(tensor.sum()) # torch.sum(tensor)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9ExwUkI-j7u",
        "outputId": "e47807ae-3dbd-43df-d665-799b69b8f822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "tensor(0)\n",
            "tensor(90)\n",
            "tensor(45.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Find the positional min and max\n",
        "print(tensor.argmin())\n",
        "print(tensor.argmax()) # return index value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t_1KlAi_pRA",
        "outputId": "9b1b0f50-f0bd-4129-f152-7c0ee5111438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0)\n",
            "tensor(9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping, stacking, squeezing and unsqueezing\n",
        "\n",
        "* Reshaping - reshapes an input tensor to a defined shape\n",
        "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
        "* Stacking(hstack, vstack) - combine multiple tensors\n",
        "* Squeeze(unsqueeze) - reemove all '1' dimensions from a tensor(unsqueeze add '1' dimension to a target tensor)\n",
        "* Permute - return a view of the input with dimensions permuted(swapped) in a certain way"
      ],
      "metadata": {
        "id": "NDUsjIuWAOSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(1.,10.)\n",
        "x_reshaped = x.reshape(1,9)\n",
        "print(x_reshaped, x_reshaped.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLoOtLZxAS76",
        "outputId": "e8fbeecd-e9ec-40d8-89dd-89d06c19f40d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]) torch.Size([1, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the view(Change z changes x (share same memory))\n",
        "z = x.view(1,9)\n",
        "z[:,0] =5\n",
        "print(z,x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ0SCEKdCN-x",
        "outputId": "eb920b8e-f12a-47a8-d346-38b76a43e51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]) tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack tensors on top of each other\n",
        "x_stacked = torch.stack([x,x,x,x], dim = 1) # dim 0 은 4*9 dim 1 = 9*4\n",
        "print(x_stacked)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS-wNVqMDAec",
        "outputId": "201da237-546d-4550-da5e-0db4a5f73cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5., 5., 5., 5.],\n",
            "        [2., 2., 2., 2.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [4., 4., 4., 4.],\n",
            "        [5., 5., 5., 5.],\n",
            "        [6., 6., 6., 6.],\n",
            "        [7., 7., 7., 7.],\n",
            "        [8., 8., 8., 8.],\n",
            "        [9., 9., 9., 9.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Squeeze(unsqueeze)\n",
        "# torch.squeeze() - removes all single dimensions from a target sensor\n",
        "print(x_reshaped.shape)\n",
        "# x_reshaped.squeeze()\n",
        "print(x_reshaped.squeeze(), x_reshaped.squeeze().shape) # '1'인 차원을 모두 제거\n",
        "\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim = 0) # dim에 따라 다른 결과\n",
        "print(x_unsqueezed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvQF8vu_EA_1",
        "outputId": "c72e1468-ec1c-41dd-d61c-8f20aa3ef110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 9])\n",
            "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]) torch.Size([9])\n",
            "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.permute - rearranges the dimensions of a target tensor -> Permute도 view 관점 같은 메모리 속 데이터를 공유하기 때문에 두 변수 중 값이 변하며 따라 변함.\n",
        "x_origin = torch.rand(size=(224,224,3)) # h * w * channel\n",
        "x_permuted = x_origin.permute(2,0,1) # 3 * 224(h) * 224(w) shift axis"
      ],
      "metadata": {
        "id": "NxrvrBDoGbj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## parameter dim을 아직 명확하게 이해하짐 못함."
      ],
      "metadata": {
        "id": "FAAbpOZDSOZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing(selecting data from tensors)\n",
        "similar to indexing with Numpy"
      ],
      "metadata": {
        "id": "hCEqzR8WUQR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(1,10)\n",
        "x = tensor.reshape(1,3,3)\n",
        "print(x)\n",
        "\n",
        "print(x[0][1][2]) # 2 -> 1 -> 0 차원 element를 return\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOR9Q56UUXj_",
        "outputId": "2baf9cb6-4bae-4586-927d-ae9d01d8522b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]])\n",
            "tensor(6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# indexing 법칙 아직 이해 못함.\n",
        "print(x[:,1])\n",
        "print(x[:, :, 2]) # 첫번째 2차원 matrix의 3번째 열을 가져와.\n",
        "print(x[0,1,1]) # 3차원의 처음 원소의 2번째 행 2번쟤 열의 값을 가져와\n",
        "\n",
        "new = torch.arange(1,9).reshape(2,4)\n",
        "print(new)\n",
        "print(new[:,1]) # 2번째 열을 가져와"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqDgTxZUWTuA",
        "outputId": "e1c185e2-e34b-4ef4-8383-a6915f810649"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4, 5, 6]])\n",
            "tensor([[3, 6, 9]])\n",
            "tensor(5)\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "tensor([2, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,2,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlWuJzoVZOXD",
        "outputId": "c3fc73d1-664d-4bfd-feeb-4bb7d54d7ab8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch tensors & Numpy\n",
        "Numpy is a popular scientific python numerical computing library.\n",
        "\n",
        "Pytorch has functionality to interact with it.\n",
        "\n",
        "* Data in Numpy -> Pytorch tensor (torch.from_numpy(ndarray)\n",
        "* Pytorch tensor -> Numpy(torch.Tensor.numpy()))"
      ],
      "metadata": {
        "id": "xRrzCZVgZ8oA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "print(array,array.dtype, tensor) # tensor의 기본 데이터타입은 float32이지만, 메소드로 numpy 배열을 받으면 float64 data type)\n",
        "print(tensor.type(torch.float32))\n",
        "\n",
        "\n",
        "tensor = torch.ones(7)\n",
        "print(tensor)\n",
        "np_array = torch.Tensor.numpy(tensor)\n",
        "print(np_array) # data type tensor의 default인 float32 유지\n",
        "\n",
        "# They don't share memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luxPHtQcaw-K",
        "outputId": "2574ee74-7b3d-4665-e872-4aedb1d5119d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 2. 3. 4. 5. 6. 7.] float64 tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n",
            "tensor([1., 2., 3., 4., 5., 6., 7.])\n",
            "tensor([1., 1., 1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reproducibility(trying to take random out of random)\n",
        "\n",
        "To reduce the randomness in neural networks and Pytorch comes the concept of a **randon seed**.\n",
        "Essentially what the random seed does is 'flavour' the randomness."
      ],
      "metadata": {
        "id": "yQF5vyAGgzEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_1 = torch.rand(3,4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_2 = torch.rand(3,4)\n",
        "\n",
        "print(random_tensor_1 == random_tensor_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyTXDMfdiI-r",
        "outputId": "3941152c-54e6-412a-de83-1f24700cde9c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running tensors and Pytorch objects on the GPUs(and making faster computations)\n",
        "\n",
        "How can we use GPUs?\n",
        "* easiset way -> Google colab\n",
        "* use my own GPUs -> takes a little bit of setup and requires the investment of purchasing a GPU\n",
        "* use Cloud computing -> GCP, AWS, Azure(rent computers on the cloud and access them)\n",
        "\n",
        "For 2,3 Pytorch+GPU drivers(CUDA) takes a little bit of setting up, refer to Pytorch setup documentation."
      ],
      "metadata": {
        "id": "FfepgbZwi_oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bop5voZdlHhl",
        "outputId": "f003483b-a44d-4eb8-a6dd-b780ddd9d833"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 24 02:47:44 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for GPU Access with Pytorch\n",
        "torch.cuda.is_available() # get access to GPU\n",
        "\n",
        "# setup device agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "Gw0fsifflcW6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting tensors(and models) on the GPU\n",
        "The reason we want our tensors/models on the GPU is because using a GPU results in faster compuations."
      ],
      "metadata": {
        "id": "H-UgWGOVmmX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# move tensor to GPU(if available)\n",
        "\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu\n",
        "\n",
        "# if tensor is on GPU, can't transform it to Numpy\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "print(tensor_back_on_cpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC-IOCWCnS-l",
        "outputId": "2427071c-8924-4e8c-a78c-5139528c0e2c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    }
  ]
}